=== Training started ===
Output dir: models/llama32-3b-qlora-finetome-exam
Batch size: 4
Grad accumulate: 4
Epochs: 2
LR: 0.0001
BF16: True
Optimizer: OptimizerNames.PAGED_ADAMW_8BIT
[step 50] loss=0.8074 lr=0.000100 | GPU alloc=2287.2MB, reserved=8644.0MB | CPU RAM=1389.7MB | elapsed=2.3min, steps/s=0.36
[step 100] loss=0.0955 lr=0.000093 | GPU alloc=2287.2MB, reserved=9498.0MB | CPU RAM=1390.6MB | elapsed=4.3min, steps/s=0.39
[step 150] loss=0.0908 lr=0.000087 | GPU alloc=2287.2MB, reserved=9498.0MB | CPU RAM=1391.0MB | elapsed=6.3min, steps/s=0.39
[step 200] loss=0.0959 lr=0.000080 | GPU alloc=2287.2MB, reserved=10388.0MB | CPU RAM=1391.1MB | elapsed=8.3min, steps/s=0.40
Checkpoint saved at step 200 → models/llama32-3b-qlora-finetome-exam
[step 250] loss=0.0957 lr=0.000074 | GPU alloc=2287.2MB, reserved=11332.0MB | CPU RAM=1415.2MB | elapsed=10.4min, steps/s=0.40
[step 300] loss=0.0997 lr=0.000067 | GPU alloc=2287.2MB, reserved=11332.0MB | CPU RAM=1415.2MB | elapsed=12.4min, steps/s=0.40
[step 350] loss=0.0958 lr=0.000061 | GPU alloc=2287.2MB, reserved=11332.0MB | CPU RAM=1415.2MB | elapsed=14.3min, steps/s=0.41
[step 400] loss=0.0889 lr=0.000054 | GPU alloc=2287.2MB, reserved=11332.0MB | CPU RAM=1415.2MB | elapsed=16.3min, steps/s=0.41
Checkpoint saved at step 400 → models/llama32-3b-qlora-finetome-exam
[step 450] loss=0.0858 lr=0.000048 | GPU alloc=2287.2MB, reserved=11382.0MB | CPU RAM=1416.7MB | elapsed=18.3min, steps/s=0.41
[step 500] loss=0.0895 lr=0.000041 | GPU alloc=2287.2MB, reserved=11382.0MB | CPU RAM=1416.7MB | elapsed=20.3min, steps/s=0.41
[step 550] loss=0.0855 lr=0.000035 | GPU alloc=2287.2MB, reserved=11382.0MB | CPU RAM=1416.7MB | elapsed=22.3min, steps/s=0.41
[step 600] loss=0.0897 lr=0.000028 | GPU alloc=2287.2MB, reserved=11382.0MB | CPU RAM=1416.7MB | elapsed=23.9min, steps/s=0.42
Checkpoint saved at step 600 → models/llama32-3b-qlora-finetome-exam
[step 650] loss=0.0906 lr=0.000021 | GPU alloc=2287.2MB, reserved=11382.0MB | CPU RAM=1417.3MB | elapsed=26.1min, steps/s=0.42
[step 700] loss=0.0857 lr=0.000015 | GPU alloc=2287.2MB, reserved=11382.0MB | CPU RAM=1417.3MB | elapsed=28.1min, steps/s=0.41
[step 750] loss=0.0845 lr=0.000008 | GPU alloc=2287.2MB, reserved=11382.0MB | CPU RAM=1417.3MB | elapsed=29.8min, steps/s=0.42
[step 800] loss=0.0846 lr=0.000002 | GPU alloc=2287.2MB, reserved=11382.0MB | CPU RAM=1417.3MB | elapsed=31.5min, steps/s=0.42
Checkpoint saved at step 800 → models/llama32-3b-qlora-finetome-exam
Checkpoint saved at step 814 → models/llama32-3b-qlora-finetome-exam
[step 814] loss=N/A lr=N/A | GPU alloc=2287.2MB, reserved=11382.0MB | CPU RAM=1418.5MB | elapsed=32.0min, steps/s=0.42
=== Training finished ===
Total steps: 814
Total wall-clock time: 0.53 hours
